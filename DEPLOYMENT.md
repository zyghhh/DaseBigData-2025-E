# Flink vs Storm At-Least-Once å¯¹æ¯”å®éªŒé¡¹ç›®

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„æµå¤„ç†ç³»ç»Ÿå¯¹æ¯”å®éªŒé¡¹ç›®ï¼Œç”¨äºè¯„ä¼° **Flink** å’Œ **Storm** åœ¨ **At-Least-Once** è¯­ä¹‰ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼ˆå»¶è¿Ÿã€é‡å¤ç‡ï¼‰ã€‚

### ç³»ç»Ÿæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data        â”‚      â”‚ Kafka        â”‚      â”‚ Flink/Storm â”‚      â”‚ Kafka        â”‚
â”‚ Generator   â”‚â”€â”€â”€â”€â”€â–¶â”‚ source_data  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Processing  â”‚â”€â”€â”€â”€â”€â–¶â”‚ *_sink       â”‚
â”‚ (Node 2)    â”‚      â”‚              â”‚      â”‚ (Node 1,2,3)â”‚      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                        â”‚
                                                                        â–¼
                                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                              â”‚ Metrics      â”‚
                                                              â”‚ Collector    â”‚
                                                              â”‚ (Node 3)     â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                        â”‚
                                                                        â–¼
                                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                              â”‚ MySQL        â”‚
                                                              â”‚ (Node 1)     â”‚
                                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒæ¨¡å—

1. **data-generator**: Kafka æ•°æ®ç”Ÿæˆå™¨ï¼Œæ¨¡æ‹Ÿæ’å®šé€Ÿç‡çš„æ•°æ®æµ
2. **experiment-job**: Flink å’Œ Storm è®¡ç®—ä»»åŠ¡ï¼Œå¼€å¯ At-Least-Once å¯é æ€§ä¿è¯
3. **metrics-collector**: æŒ‡æ ‡æ”¶é›†å™¨ï¼Œç»Ÿè®¡å»¶è¿Ÿå’Œé‡å¤ç‡

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

ç¡®ä¿ä»¥ä¸‹æœåŠ¡å·²åœ¨é›†ç¾¤ä¸­æ­£ç¡®éƒ¨ç½²ï¼š

- **Kafka** (Node 1, 2, 3): ç«¯å£ 9092
- **Flink** (Node 1): JobManager + TaskManager (4 Slots)
- **Storm** (Node 1): Nimbus; (Node 2, 3): Supervisor (å„2ä¸ªWorkerç«¯å£)
- **MySQL** (Node 1): ç«¯å£ 3306
- **Java 8** å·²å®‰è£…åœ¨æ‰€æœ‰èŠ‚ç‚¹

### 2. é…ç½® /etc/hosts

åœ¨ **Node 2** å’Œ **Node 3** ä¸Šé…ç½®ä¸»æœºåæ˜ å°„ï¼š

```bash
sudo vim /etc/hosts

# æ·»åŠ ä»¥ä¸‹å†…å®¹ (æ›¿æ¢ä¸ºå®é™…å†…ç½‘ IP)
192.168.1.101  node1
192.168.1.102  node2
192.168.1.103  node3
```

### 3. åˆå§‹åŒ–æ•°æ®åº“

åœ¨ **Node 1** ä¸Šæ‰§è¡Œï¼š

```bash
# ä¿®æ”¹ database/init.sh ä¸­çš„ root å¯†ç 
vim database/init.sh  # ä¿®æ”¹ MYSQL_ROOT_PASSWORD

# æ‰§è¡Œåˆå§‹åŒ–
bash database/init.sh

# æˆ–æ‰‹åŠ¨æ‰§è¡Œ
mysql -u root -p < database/init.sql
```

éªŒè¯ï¼š

```bash
mysql -h node1 -u exp_user -ppassword stream_experiment -e "SELECT * FROM v_latency_stats;"
```

### 4. ç¼–è¯‘é¡¹ç›®

åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œï¼š

```bash
mvn clean package

# ç”Ÿæˆçš„ jar åŒ…ï¼š
# - data-generator/target/data-generator.jar
# - experiment-job/target/experiment-job.jar
# - metrics-collector/target/metrics-collector.jar
```

---

## ğŸ“¦ éƒ¨ç½²ä¸è¿è¡Œ

### æ­¥éª¤ 1: å¯åŠ¨æ•°æ®ç”Ÿæˆå™¨ï¼ˆNode 2ï¼‰

```bash
# ä¸Šä¼  jar åŒ…åˆ° Node 2
scp data-generator/target/data-generator.jar user@node2:/opt/experiment/

# åœ¨ Node 2 ä¸Šå¯åŠ¨ï¼ˆæ¯ç§’ 1500 æ¡æ¶ˆæ¯ï¼‰
ssh node2
cd /opt/experiment
nohup java -Xmx512m -jar data-generator.jar source_data 1500 > generator.log 2>&1 &
```

éªŒè¯ï¼š

```bash
tail -f generator.log
# åº”çœ‹åˆ° "Data Generator Started" å’Œå®šæœŸçš„ç»Ÿè®¡ä¿¡æ¯
```

### æ­¥éª¤ 2A: è¿è¡Œ Flink å®éªŒ

#### 2A.1 æäº¤ Flink Job (Node 1)

```bash
# ä¸Šä¼  jar åŒ…åˆ° Node 1
scp experiment-job/target/experiment-job.jar user@node1:/opt/flink/

# åœ¨ Node 1 ä¸Šæäº¤ä»»åŠ¡
ssh node1
cd /opt/flink
./bin/flink run -d -c com.dase.bigdata.job.FlinkAtLeastOnceJob experiment-job.jar
```

éªŒè¯ï¼š

```bash
./bin/flink list
# æŸ¥çœ‹ Web UI: http://node1:8081
```

#### 2A.2 å¯åŠ¨æŒ‡æ ‡æ”¶é›†å™¨ (Node 3)

```bash
# ä¸Šä¼  jar åŒ…åˆ° Node 3
scp metrics-collector/target/metrics-collector.jar user@node3:/opt/experiment/

# åœ¨ Node 3 ä¸Šå¯åŠ¨
ssh node3
cd /opt/experiment
nohup java -Xmx512m -jar metrics-collector.jar flink_sink flink > collector-flink.log 2>&1 &
```

éªŒè¯ï¼š

```bash
tail -f collector-flink.log
# åº”çœ‹åˆ° "Metrics Collector Started" å’Œå®šæœŸçš„ç»Ÿè®¡ä¿¡æ¯
```

#### 2A.3 è¿è¡Œå®éªŒï¼ˆå»ºè®® 10 åˆ†é’Ÿï¼‰

ç­‰å¾… 10 åˆ†é’Ÿï¼Œè®©ç³»ç»Ÿç§¯ç´¯è¶³å¤Ÿæ•°æ®...

#### 2A.4 æŸ¥çœ‹ Flink å®éªŒç»“æœ

```bash
mysql -h node1 -u exp_user -ppassword stream_experiment -e "
SELECT * FROM v_latency_stats WHERE ä»»åŠ¡ç±»å‹='flink';
SELECT * FROM v_duplicate_stats WHERE ä»»åŠ¡ç±»å‹='flink';
"
```

#### 2A.5 åœæ­¢ Flink å®éªŒ

```bash
# åœæ­¢ Flink Job
ssh node1
cd /opt/flink
./bin/flink list
./bin/flink cancel <job-id>

# åœæ­¢æŒ‡æ ‡æ”¶é›†å™¨
ssh node3
pkill -f metrics-collector
```

### æ­¥éª¤ 2B: è¿è¡Œ Storm å®éªŒ

#### 2B.1 å¤ä½å®éªŒç¯å¢ƒ

```bash
# æ¸…ç©ºæ•°æ®åº“
mysql -h node1 -u exp_user -ppassword stream_experiment -e "CALL sp_reset_experiment();"

# é‡ç½® Kafka Topic Offset (å¯é€‰)
ssh node1
kafka-consumer-groups.sh --bootstrap-server node1:9092 --group storm-exp-group --reset-offsets --to-earliest --topic source_data --execute
```

#### 2B.2 è°ƒæ•´ Storm Worker é…ç½® (Node 2 & Node 3)

```bash
# åœ¨ Node 2 å’Œ Node 3 ä¸Šç¼–è¾‘ storm.yaml
ssh node2
sudo vim /opt/storm/conf/storm.yaml

# ä¿®æ”¹ Worker ç«¯å£é…ç½®
supervisor.slots.ports:
    - 6700
    - 6701

# é‡å¯ Supervisor
sudo systemctl restart storm-supervisor

# åœ¨ Node 3 ä¸Šé‡å¤ç›¸åŒæ“ä½œ
```

#### 2B.3 æäº¤ Storm Topology (Node 1)

```bash
# åœ¨ Node 1 ä¸Šæäº¤
ssh node1
cd /opt/storm
./bin/storm jar /opt/flink/experiment-job.jar com.dase.bigdata.job.StormAtLeastOnceTopology Storm-AtLeastOnce-Test
```

éªŒè¯ï¼š

```bash
./bin/storm list
# æŸ¥çœ‹ Web UI: http://node1:8080
```

#### 2B.4 å¯åŠ¨æŒ‡æ ‡æ”¶é›†å™¨ (Node 3)

```bash
ssh node3
cd /opt/experiment
nohup java -Xmx512m -jar metrics-collector.jar storm_sink storm > collector-storm.log 2>&1 &
```

#### 2B.5 è¿è¡Œå®éªŒï¼ˆå»ºè®® 10 åˆ†é’Ÿï¼‰

ç­‰å¾… 10 åˆ†é’Ÿ...

#### 2B.6 æŸ¥çœ‹ Storm å®éªŒç»“æœ

```bash
mysql -h node1 -u exp_user -ppassword stream_experiment -e "
SELECT * FROM v_latency_stats WHERE ä»»åŠ¡ç±»å‹='storm';
SELECT * FROM v_duplicate_stats WHERE ä»»åŠ¡ç±»å‹='storm';
"
```

#### 2B.7 åœæ­¢ Storm å®éªŒ

```bash
# åœæ­¢ Storm Topology
ssh node1
cd /opt/storm
./bin/storm kill Storm-AtLeastOnce-Test

# åœæ­¢æŒ‡æ ‡æ”¶é›†å™¨
ssh node3
pkill -f metrics-collector
```

### æ­¥éª¤ 3: å¯¹æ¯”åˆ†æ

æŸ¥çœ‹ä¸¤ä¸ªç³»ç»Ÿçš„ç»¼åˆå¯¹æ¯”ï¼š

```bash
mysql -h node1 -u exp_user -ppassword stream_experiment -e "SELECT * FROM v_comparison;"
```

ç¤ºä¾‹è¾“å‡ºï¼š

```
+------------+--------------+------------------+--------------+------------------+
| ä»»åŠ¡ç±»å‹   | æ€»æ¶ˆæ¯æ•°     | å¹³å‡å»¶è¿Ÿ(ms)     | é‡å¤ç‡(%)    | æœ€å¤§é‡å¤æ¬¡æ•°     |
+------------+--------------+------------------+--------------+------------------+
| flink      |       900000 |           45.23  |         0.15 |                2 |
| storm      |       900000 |           52.67  |         1.23 |                3 |
+------------+--------------+------------------+--------------+------------------+
```

---

## ğŸ”§ å…³é”®é…ç½®è¯´æ˜

### Flink At-Least-Once é…ç½®

- **Checkpoint é—´éš”**: 5ç§’
- **Checkpoint æ¨¡å¼**: `AT_LEAST_ONCE`
- **å¹¶å‘åº¦**: 4
- **ä¸šåŠ¡å¤„ç†å»¶è¿Ÿ**: 2ms

### Storm At-Least-Once é…ç½®

- **Acker æ•°é‡**: 1
- **Worker æ•°é‡**: 4
- **Spout å¹¶å‘**: 1
- **Process Bolt å¹¶å‘**: 2
- **Sink Bolt å¹¶å‘**: 1
- **ä¸šåŠ¡å¤„ç†å»¶è¿Ÿ**: 2ms

### æ•°æ®ç”Ÿæˆå™¨é…ç½®

- **æ¶ˆæ¯é€Ÿç‡**: 1500 msg/sï¼ˆå¯è°ƒæ•´ï¼‰
- **æ¶ˆæ¯å¤§å°**: çº¦ 1KB
- **æ¶ˆæ¯æ ¼å¼**: JSON (åŒ…å« msg_id, create_time, payload)

### æŒ‡æ ‡æ”¶é›†å™¨é…ç½®

- **æ‰¹é‡æäº¤**: æ¯æ¬¡ poll åæ‰¹é‡å†™å…¥ MySQL
- **é‡å¤æ£€æµ‹**: åˆ©ç”¨ MySQL å”¯ä¸€ç´¢å¼• (job_type, msg_id)
- **å»¶è¿Ÿè®¡ç®—**: out_time - create_time

---

## ğŸ“Š æ•°æ®åˆ†æ

### å¸¸ç”¨æŸ¥è¯¢

```sql
-- 1. æŸ¥çœ‹å»¶è¿Ÿç»Ÿè®¡
SELECT * FROM v_latency_stats;

-- 2. æŸ¥çœ‹é‡å¤ç‡ç»Ÿè®¡
SELECT * FROM v_duplicate_stats;

-- 3. æŸ¥çœ‹ç»¼åˆå¯¹æ¯”
SELECT * FROM v_comparison;

-- 4. æŸ¥çœ‹ Flink çš„é‡å¤æ¶ˆæ¯è¯¦æƒ…
CALL sp_get_duplicates('flink');

-- 5. æŸ¥çœ‹ Storm çš„å»¶è¿Ÿåˆ†å¸ƒ
CALL sp_get_latency_distribution('storm');

-- 6. æŸ¥è¯¢ç‰¹å®šæ¶ˆæ¯çš„å¤„ç†è®°å½•
SELECT * FROM metrics WHERE msg_id = 12345 ORDER BY job_type;

-- 7. å®éªŒå¤ä½
CALL sp_reset_experiment();
```

### å¯¼å‡ºå®éªŒæ•°æ®

```bash
# å¯¼å‡ºåˆ° CSV
mysql -h node1 -u exp_user -ppassword stream_experiment -e "
SELECT * FROM v_comparison;" > comparison_result.csv

# å¯¼å‡ºå®Œæ•´æ•°æ®
mysqldump -h node1 -u exp_user -ppassword stream_experiment metrics > metrics_dump.sql
```

---

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æ•°æ®ç”Ÿæˆå™¨æ— æ³•è¿æ¥ Kafka

```bash
# æ£€æŸ¥ Kafka æ˜¯å¦è¿è¡Œ
ssh node1
jps | grep Kafka

# æ£€æŸ¥ /etc/hosts é…ç½®
cat /etc/hosts | grep node

# æµ‹è¯•ç½‘ç»œè¿é€šæ€§
telnet node1 9092
```

### é—®é¢˜ 2: Flink Job æäº¤å¤±è´¥

```bash
# æ£€æŸ¥ Flink é›†ç¾¤çŠ¶æ€
./bin/flink list

# æŸ¥çœ‹ JobManager æ—¥å¿—
tail -f log/flink-*-jobmanager-*.log

# æ£€æŸ¥ TaskManager Slots
# Web UI: http://node1:8081/#/task-managers
```

### é—®é¢˜ 3: æŒ‡æ ‡æ”¶é›†å™¨æ— æ•°æ®

```bash
# æ£€æŸ¥ Kafka Topic æ˜¯å¦æœ‰æ•°æ®
kafka-console-consumer.sh --bootstrap-server node1:9092 --topic flink_sink --from-beginning --max-messages 10

# æ£€æŸ¥æ•°æ®åº“è¿æ¥
mysql -h node1 -u exp_user -ppassword stream_experiment -e "SELECT COUNT(*) FROM metrics;"

# æŸ¥çœ‹æ—¥å¿—
tail -f collector-flink.log
```

### é—®é¢˜ 4: Storm Worker ä¸è¶³

```bash
# æ£€æŸ¥ Supervisor é…ç½®
ssh node2
cat /opt/storm/conf/storm.yaml | grep slots.ports

# é‡å¯ Supervisor
sudo systemctl restart storm-supervisor

# æŸ¥çœ‹ Storm UI
# http://node1:8080
```

---

## ğŸ“ å®éªŒæŠ¥å‘Šæ¨¡æ¿

### 1. å®éªŒç¯å¢ƒ

| ç»„ä»¶   | ç‰ˆæœ¬   | èŠ‚ç‚¹åˆ†å¸ƒ      | é…ç½®å‚æ•°         |
|--------|--------|---------------|------------------|
| Kafka  | 2.8.0  | Node 1,2,3    | 3 Brokers        |
| Flink  | 1.14.6 | Node 1        | 4 Slots          |
| Storm  | 2.4.0  | Node 1,2,3    | 4 Workers        |
| MySQL  | 8.0    | Node 1        | InnoDB           |

### 2. å®éªŒå‚æ•°

- **æ•°æ®é€Ÿç‡**: 1500 msg/s
- **æ¶ˆæ¯å¤§å°**: 1KB
- **ä¸šåŠ¡å»¶è¿Ÿ**: 2ms
- **å®éªŒæ—¶é•¿**: 10 åˆ†é’Ÿ
- **Checkpointé—´éš”**: 5s

### 3. å®éªŒç»“æœ

| æŒ‡æ ‡           | Flink    | Storm    | å¯¹æ¯”     |
|----------------|----------|----------|----------|
| å¹³å‡å»¶è¿Ÿ (ms)  | 45.23    | 52.67    | Flink ä¼˜ |
| é‡å¤ç‡ (%)     | 0.15     | 1.23     | Flink ä¼˜ |
| ååé‡ (msg/s) | 1498     | 1495     | ç›¸è¿‘     |

### 4. ç»“è®º

ï¼ˆæ ¹æ®å®é™…æ•°æ®å¡«å†™ï¼‰

---

## ğŸ”’ å®‰å…¨æ³¨æ„äº‹é¡¹

1. **æ•°æ®åº“å¯†ç **: è¯·ä¿®æ”¹ `database/init.sql` å’Œ `MetricsCollector.java` ä¸­çš„é»˜è®¤å¯†ç 
2. **ç½‘ç»œéš”ç¦»**: å»ºè®®åœ¨å†…ç½‘ç¯å¢ƒè¿è¡Œï¼Œé¿å…æš´éœ²åˆ°å…¬ç½‘
3. **èµ„æºé™åˆ¶**: å¯åŠ¨ jar åŒ…æ—¶å·²é™åˆ¶ JVM å†…å­˜ï¼ˆ512Mï¼‰ï¼Œé¿å…èµ„æºæŠ¢å 

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Flink Checkpointing æ–‡æ¡£](https://nightlies.apache.org/flink/flink-docs-release-1.14/docs/dev/datastream/fault-tolerance/checkpointing/)
- [Storm Guarantees æ–‡æ¡£](https://storm.apache.org/releases/current/Guaranteeing-message-processing.html)
- [Kafka Producer é…ç½®](https://kafka.apache.org/documentation/#producerconfigs)

---

## ğŸ‘¥ é¡¹ç›®ä¿¡æ¯

- **é¡¹ç›®åç§°**: Flink vs Storm At-Least-Once å¯¹æ¯”å®éªŒ
- **ç‰ˆæœ¬**: 1.0-SNAPSHOT
- **è®¸å¯**: Apache License 2.0

---

## ğŸ“ é—®é¢˜åé¦ˆ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
1. å„èŠ‚ç‚¹çš„ `/etc/hosts` é…ç½®
2. æ‰€æœ‰æœåŠ¡ï¼ˆKafka, Flink, Storm, MySQLï¼‰çš„è¿è¡ŒçŠ¶æ€
3. é˜²ç«å¢™å’Œç½‘ç»œç«¯å£æ˜¯å¦å¼€æ”¾
4. æ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯ä¿¡æ¯
